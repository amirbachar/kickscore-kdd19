{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impact of mean-field assumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kickscore as ks\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime, timezone, timedelta\n",
    "from kseval.models import iterate_dataset\n",
    "from kseval.models.base import YEAR\n",
    "from kseval.models.basketball import DATASET\n",
    "from kseval.regression import DynamicLinearRegression\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams = [\n",
    "    \"ATL\", \"BOS\", \"CHH\", \"CHI\", \"CHO\", \"CLE\", \"DAL\", \"DEN\", \"DET\", \"GSW\", \"HOU\",\n",
    "    \"IND\", \"LAC\", \"LAL\", \"MEM\", \"MIA\", \"MIL\", \"MIN\", \"NJN\", \"NOP\", \"NYK\", \"ORL\",\n",
    "    \"PHI\", \"PHO\", \"POR\", \"SAC\", \"SAS\", \"SEA\", \"TOR\", \"UTA\", \"VAN\", \"WAS\", \n",
    "]\n",
    "M = len(teams)\n",
    "team2id = dict(zip(teams, range(M)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "kern = (ks.kernel.Constant(var=0.05931)\n",
    "        + ks.kernel.Exponential(var=17.66673, lscale=(3.31032*YEAR)))\n",
    "\n",
    "begin = datetime(2000, 8, 1, tzinfo=timezone.utc).timestamp()\n",
    "cutoff = datetime(2004, 8, 1, tzinfo=timezone.utc)\n",
    "bounds = [(cutoff + timedelta(days=5*i)).timestamp() for i in range(70)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(X1, t1, y1, X2, t2, y2):\n",
    "    if len(X2) == 0:\n",
    "        return 0, 0, 0\n",
    "    n_obs, log_loss, accuracy = 0, 0, 0\n",
    "    reg = DynamicLinearRegression(time_kern=kern, noise_var=143.45175)\n",
    "    reg.fit(X1, t1, y1)\n",
    "    prob = reg.probabilities(X2, t2)\n",
    "    for y, p in zip(y2, prob):\n",
    "        if y > 0:\n",
    "            log_loss += -log(p)\n",
    "            accuracy += 1.0 if p > 0.5 else 0.0\n",
    "        else:\n",
    "            log_loss += -log(1 - p)\n",
    "            accuracy += 1.0 if 1 - p > 0.5 else 0.0\n",
    "        n_obs += 1\n",
    "    return n_obs, log_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".....................................................................\n",
      "CPU times: user 6min 45s, sys: 1min 16s, total: 8min 2s\n",
      "Wall time: 5min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fc = {\"n_obs\": 0, \"accuracy\": 0, \"log_loss\": 0}\n",
    "\n",
    "for t1, t2 in zip(bounds[:-1], bounds[1:]):\n",
    "    print(\".\", end=\"\")\n",
    "    X_train, X_test = list(), list()\n",
    "    t_train, t_test = list(), list()\n",
    "    y_train, y_test = list(), list()\n",
    "    for obs in iterate_dataset(DATASET):\n",
    "        if obs[\"t\"] < begin or obs[\"t\"] >= t2:\n",
    "            continue\n",
    "        vec = np.zeros(M)\n",
    "        vec[team2id[obs[\"team1\"]]] = +1\n",
    "        vec[team2id[obs[\"team2\"]]] = -1\n",
    "        if obs[\"t\"] < t1:\n",
    "            X_train.append(vec)\n",
    "            y_train.append(obs[\"score1\"] - obs[\"score2\"])\n",
    "            t_train.append(obs[\"t\"])\n",
    "        else:\n",
    "            X_test.append(vec)\n",
    "            y_test.append(obs[\"score1\"] - obs[\"score2\"])\n",
    "            t_test.append(obs[\"t\"])\n",
    "    res = evaluate(\n",
    "        np.array(X_train), np.array(t_train), np.array(y_train),\n",
    "        np.array(X_test), np.array(t_test), np.array(y_test))\n",
    "    fc[\"n_obs\"] += res[0]\n",
    "    fc[\"log_loss\"] += res[1]\n",
    "    fc[\"accuracy\"] += res[2]\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log loss: 0.634\n",
      "accuracy: 0.664\n"
     ]
    }
   ],
   "source": [
    "print(\"log loss: {:.3f}\".format(fc[\"log_loss\"] / fc[\"n_obs\"]))\n",
    "print(\"accuracy: {:.3f}\".format(fc[\"accuracy\"] / fc[\"n_obs\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean-field approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".....................................................................\n",
      "CPU times: user 11min 19s, sys: 1min 42s, total: 13min 2s\n",
      "Wall time: 6min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mf = {\"n_obs\": 0, \"accuracy\": 0, \"log_loss\": 0}\n",
    "\n",
    "model = ks.DifferenceModel(var=143.45175)\n",
    "for team in teams:\n",
    "    model.add_item(team, kernel=kern)\n",
    "    \n",
    "for obs in iterate_dataset(DATASET):\n",
    "    if obs[\"t\"] < begin:\n",
    "        continue\n",
    "    elif obs[\"t\"] < bounds[0]:\n",
    "        diff = obs[\"score1\"] - obs[\"score2\"]\n",
    "        model.observe([obs[\"team1\"]], [obs[\"team2\"]], diff=diff, t=obs[\"t\"])\n",
    "    else:\n",
    "        break\n",
    "\n",
    "for i in range(len(bounds) - 1):\n",
    "    print(\".\", end=\"\")\n",
    "    fitted = False\n",
    "    for obs in iterate_dataset(DATASET):\n",
    "        if i == 0 or obs[\"t\"] < bounds[i-1]:\n",
    "            continue\n",
    "        elif obs[\"t\"] < bounds[i]:\n",
    "            diff = obs[\"score1\"] - obs[\"score2\"]\n",
    "            model.observe([obs[\"team1\"]], [obs[\"team2\"]], diff=diff, t=obs[\"t\"])\n",
    "        elif obs[\"t\"] < bounds[i+1]:\n",
    "            if not fitted:\n",
    "                model.fit()\n",
    "            diff = obs[\"score1\"] - obs[\"score2\"]\n",
    "            p1, p2 = model.probabilities([obs[\"team1\"]], [obs[\"team2\"]], t=obs[\"t\"])\n",
    "            if diff > 0:\n",
    "                mf[\"log_loss\"] += -log(p1)\n",
    "                mf[\"accuracy\"] += 1.0 if p1 > 0.5 else 0.0\n",
    "            else:\n",
    "                mf[\"log_loss\"] += -log(p2)\n",
    "                mf[\"accuracy\"] += 1.0 if p2 > 0.5 else 0.0\n",
    "            mf[\"n_obs\"] += 1\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log loss: 0.634\n",
      "accuracy: 0.664\n"
     ]
    }
   ],
   "source": [
    "print(\"log loss: {:.3f}\".format(mf[\"log_loss\"] / mf[\"n_obs\"]))\n",
    "print(\"accuracy: {:.3f}\".format(mf[\"accuracy\"] / mf[\"n_obs\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity check against GPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-10.263342174517508"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([\n",
    "    [1.0, -1.0],\n",
    "    [-1.0, 1.0],\n",
    "])\n",
    "t = np.array([0.0, 1.0])\n",
    "y = np.array([1.7, 2.3])\n",
    "\n",
    "kern = ks.kernel.Constant(var=1.0)\n",
    "reg = DynamicLinearRegression(time_kern=kern, noise_var=0.5)\n",
    "\n",
    "reg.fit(X, t, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.26666667,  0.26666667]), array([0.72222222, 0.72222222]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu, var = reg.predict(X, t)\n",
    "mu, var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-10.263342025584178"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import GPy\n",
    "kern = GPy.kern.Linear(input_dim=2)\n",
    "m = GPy.models.GPRegression(X=X, Y=y[:,None], kernel=kern, noise_var=0.5)\n",
    "m.log_likelihood()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.26666667],\n",
       "        [ 0.26666667]]), array([[0.72222223],\n",
       "        [0.72222223]]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Big case:\n",
    "\n",
    "    import GPy\n",
    "    kern = (GPy.kern.Linear(input_dim=32, active_dims=list(range(1, 33)))\n",
    "            * (GPy.kern.Bias(input_dim=1, active_dims=[0], variance=0.05931)\n",
    "                    + GPy.kern.Exponential(input_dim=1, active_dims=[0],\n",
    "                            variance=17.66673, lengthscale=3.31032)))\n",
    "    m = GPy.models.GPRegression(X=np.hstack((t[:,None]/YEAR, X)), Y=y[:,None], kernel=kern, noise_var=143.45175)\n",
    "    m.log_likelihood()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
